<div class="container" id="social">
  <br>
  <br>
  <figure class="text-center">
    <blockquote class="blockquote">
      <p>Activism is my rent for living on the planet!</p>
    </blockquote>
    <figcaption class="blockquote-footer">
      <cite title="Source Title">Alice Walker</cite>
    </figcaption>
  </figure>
  <br>
  <h3>Activism, Citizenry and Ethics in Software</h3>
  <br>
  <p>
    Maybe we can't all be as as effective in our opposition as Martin Luther King; nevertheless, as citizens of a
    world community, we have a responsibility to our communities! As engineers and
    software developers, we are often the last line of defense against unethical, dangerous and in some cases, predatory
    practices. Computing devices and software play an integral role in every aspect of our daily lives, the more
    critical it is and becomes for us to be vigilant about what we are building
    for consumption and ensure we aren't silent when our morals or ethics are in conflict with what we want to represent
    in the software we build.
  </p>
  <p>
    I want to share one story from my journey and perhaps a pivotal step in my transition to "a man"; furthermore, how
    I've come to perceive my responsibility as a software developer and a citizen.
  </p>
  <img
    src="https://cdn.theatlantic.com/thumbor/kMZbQT0JJKFzr4mN_HPyO13C8-w=/0x0:2000x1125/1920x1080/media/img/2018/02/09/Lewis_lead/original.jpg"
    class="rebel">
  <hr>
  <p>
    I feel like I've officially been a software developer (non-imposter) since 2004 and although my formal title at the firm that
    employees me is not
    that, I produce new source code almost every day. Now, how I've come to
    this role is a bit unorthodox in fact, but ultimately my journey started as an auto body repair technician--thru to
    working on running fibre optic cables, to fixing computer hardware, to UNIX systems administration, then app-dev
    and now to coaching teams towards business agility and engineering acumen such that they can build awesome products
    and become cross-functional business and engineering teams.
  </p>

  <p>By the time I was 26, I considered myself a seasoned systems and app-dev consultant. I interviewed
    for and was hired as a senior software developer with an interactive pharmaceutical company based in Canada
    with connections to a Minnesota IT consulting firm. In Canada, there are strict limits on
    how firms can advertise prescription drugs to its clients and potential consumers. As a result, this company
    would sub-contract a portion of the product marketing and software development to other businesses--like the consulting
    firm where I worked as a software developer.
  </p>
  <p>
    As a senior developer, it was my responsibility to create a series of web applications for the pharmaceutical firm. As
    one of my first tasks was to develop a health survey-part of a larger web portal that would elicit health data
    related to a set of health symptoms. This information in the survey was authored
    to give an <strong>appearance of presenting general information</strong> about symptoms-the exact same ones
    the pharmaceutical companies drugs were meant to address.
    Important to note, the information contained in this portal specifically targeted black and brown men,
    between the ages of 26 and 45 years old. The survey elicits information from a "potential customer", and the
    feedback based on a set of symptoms a patient may be experiencing. Now, you might think the recommendation would largely
    have decisions based on the user responses; moreover, all responses lead to the same recommendation.
    When I re-read the requirements, they contained questions and answers--no rules for what should occur, the basis of those answers. All responses led to a recommendation
    for the pharmaceutical companies' medication. After coding this prototype, the only exception to the
    rules that would not lead to a recommendation was A.) you are already taking this medication or B.) known allergy.
  </p>
  <p>I wish I could tell you I felt bad about my role in building
    software that intentionally deceived its users-men like me, men of color, but the truth is, in my youth,
    I coded to live and was oblivious to the downstream impact. The work I was doing was not illegal, I was
    just building software... right? I chalked it up to work of a marketing firm and moved on with learnings.
    I recall a good friend and I having a few conversations about this software, she would ask "Do you
    not feel a little weird about developing this type of software product?", to which I responded "I don't know. Look
    at the opportunity to learn and the pay is great!".
    We released the web application shortly before Christmas 2011 and the client was extremely delighted with the
    output of my efforts, as a result, they invited me and my team to an expensive dinner at Ruth Chris steak house in
    downtown Minneapolis. The
    SVP of Marketing wanted to know who I was, and thank me personally, invited me to bring my family. My girlfriend and I were the only minorities
    in attendance at that dinner. We were a spectacle, there was my manager asked my
    girlfriend--who was an
    accomplished professional in her own right, and said, "The software you developed is so good. We got to find her
    some work todo too, maybe in the mail room filing papers or something?" When I heard this comment, I almost laughed and almost spit up like a baby, yet,
    quietly smiled and kept quiet. That was a long dinner, I remember trying to smile--all the while feeling more guilty
    about my contributions.
  </p>
  <p>
    Three months later, a colleague emailed me a link to a news article about a man that had taken the drug from the
    pharmaceutical company we'd built the software for. The man from the article had committed suicide.
    It turned out, one of the main side effects of that drug were suicidal thoughts, headaches and depression.
    This information pushed me over the edge, as this was the event, that changed my perspective. Shortly after,
    I resigned from that firm. There are a myriad of opportunities for me to rationalize the role I played in
    building that software, and chalk it up to "doing my job", but the truth is, in those moments I was oblivious, and
    my principles
    in programming weren't aware the inherent problems,
    yet knew something didn't feel right. I never felt okay about developing that piece of software.
  </p>
  <hr>
  <img src="https://www.thehumanfront.com/assets/PocketsizedPhilosophy/66%20Minority%20Report/wilson_minority.jpg"
       class="rebel">
  <br>
  <br>
  <p>
    In 2023, software is used to configure and control most hardware apparatuses in some way. We have self driving cars
    that require
    millions of lines of code to function according to specifications and we shouldn't have concerns about the
    ethics involved.
    The value of ethics in building software is easily visible in a 120,000 thousand dollar Tesla, and when we have a software release that disables one or more
    features of a such an expensive piece of metal. Software is used in machine learning and artificial intelligence to
    train algorithms to
    diagnose cancer and other diseases and sickness. Imagine all the terror that can occur the result of development
    teams that
    don't have a set of principles they adhere to? We cannot afford to relax our principles in software ethics, as the
    problem only
    cascades from here, and can put our immediate safety in danger.
  </p>
  <p>In software engineering (and many other aspects of engineering), it is important to be aware of the
    ethical implications of the work we do. As
    developers, we have the power to shape the technology that impacts our daily lives, and it is our responsibility to
    ensure that the software we build is not dangerous or predatory.
  </p>


  <p>This experience was a turning point for me and made me realize the importance of being vigilant and
    aware of the downstream impact of the technology we create. It also reinforced the importance of speaking up when
    our morals and ethics are in conflict with the software we are building.</p>
  <p>Another software that's gaining traction and can impact the our lives in significant but unknown ways is ChatGpt. Here's a machine learning model and as such,
    not inherently controversial, but <i>boy-oh-boy</i>; like any technology, it can be used in ways that might scare you--are certainly controversial; moreover, undermine ethics.
    Many people like myself, already have concerns about the use of large language models like ChatGPT for automated content
    generation, as it raises questions about the authenticity and trustworthiness of the generated content; moreover, has already been a hotbed
    of controversy in New York city schools.
    Additionally, there are concerns about the ethical implications of using large language models like ChatGPT in
    applications such as chat bots, as it raises questions about transparency and accountability.</p>
  <img src="https://storage.googleapis.com/lablab-static-eu/images/tutorials/chatgpt-tutorial.JPG" class="rebel">
  <hr>
  <br>
  <br>
  <p>As software engineers, we must be vigilant and act when our morals or ethics are in conflict
    with the work we are asked to produce and the products we provide. We must strive to make and leave our communities
    better than we inherited them,
    and that starts with being aware of the immediate and long-term impact of the software we build.
  </p>
  <br>
  <br>
  <br>
  <br>
</div>
